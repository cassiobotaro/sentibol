{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from emoticons import (positive_emoticons, negative_emoticons, positive_sentiment, negative_sentiment)\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/cassiobotaro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cassiobotaro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassiobotaro/.virtualenvs/sentibol/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "classificator = SVC(kernel='linear')\n",
    "\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o são paulo',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "labels = [1, 1, -1, -1, 0, 0]\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('portuguese'),\n",
    "                                analyzer='word', ngram_range=(1, 1),\n",
    "                                lowercase=True, use_idf=True,\n",
    "                                strip_accents='unicode')\n",
    "\n",
    "features = tf_vectorizer.fit_transform(training_set)\n",
    "classificator.fit(features, labels)\n",
    "\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro']\n",
    "\n",
    "vector_tweets = tf_vectorizer.transform(tweets)\n",
    "predictions = classificator.predict(vector_tweets)\n",
    "\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n"
     ]
    }
   ],
   "source": [
    "classificator = MultinomialNB(alpha=.01)\n",
    "\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o sport',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "labels = [1, 1, -1, -1, 0, 0]\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('portuguese'),\n",
    "                                analyzer='word', ngram_range=(1, 1),\n",
    "                                lowercase=True, use_idf=True,\n",
    "                                strip_accents='unicode')\n",
    "\n",
    "features = tf_vectorizer.fit_transform(training_set)\n",
    "classificator.fit(features, labels)\n",
    "\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro']\n",
    "\n",
    "vector_tweets = tf_vectorizer.transform(tweets)\n",
    "predictions = classificator.predict(vector_tweets)\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n",
      "cruzeiro! :) -> 1\n",
      "Jogo morno entre cruzeiro e são paulo -> 0\n",
      "Meu sport perdeu hoje :'( -> -1\n"
     ]
    }
   ],
   "source": [
    "# lists based on https://en.wikipedia.org/wiki/List_of_emoticons\n",
    "# Versão original removia pontuação(o que é errado, pois emoticons são feitos utilizando pontuação)\n",
    "# falta de emojis\n",
    "# deveria trazer as palavras a sua raiz\n",
    "\n",
    "list_emoticons_positive = positive_emoticons.split('\\n')\n",
    "list_emoticons_negative = negative_emoticons.split('\\n')\n",
    "list_negative = negative_sentiment.split('\\n')\n",
    "list_positive = positive_sentiment.split('\\n')\n",
    "\n",
    "\n",
    "def classify(text):\n",
    "    for t in text.split(' '):\n",
    "        if t in list_emoticons_positive:\n",
    "            return 1\n",
    "        elif t in list_emoticons_negative:\n",
    "            return -1\n",
    "    return votation(text)\n",
    "\n",
    "\n",
    "def votation(text):\n",
    "    vote = 0\n",
    "    text = clean_text(text)\n",
    "\n",
    "    for t in text:\n",
    "        if t in list_negative:\n",
    "            vote = vote - 1\n",
    "        elif t in list_positive:\n",
    "            vote = vote + 1\n",
    "\n",
    "    if vote > 1:\n",
    "        return 1\n",
    "    elif vote < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return vote\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    token_text = word_tokenize(text.lower())\n",
    "    text = (word for word in token_text\n",
    "            if word not in stopwords.words('portuguese'))\n",
    "    return text\n",
    "\n",
    "\n",
    "def predict(tweets):\n",
    "    return np.array([classify(phrase) for phrase in tweets])\n",
    "\n",
    "\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro', 'cruzeiro! :)',\n",
    "          'Jogo morno entre cruzeiro e são paulo',\n",
    "          'Meu sport perdeu hoje :\\'(']\n",
    "\n",
    "predictions = predict(tweets)\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cassiobotaro/.virtualenvs/sentibol/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ate', 'eramos', 'estao', 'estavamos', 'estiveramos', 'estivessemos', 'foramos', 'fossemos', 'ha', 'hao', 'houveramos', 'houverao', 'houveriamos', 'houvessemos', 'ja', 'nao', 'sao', 'sera', 'serao', 'seriamos', 'so', 'tambem', 'tera', 'terao', 'teriamos', 'tinhamos', 'tiveramos', 'tivessemos', 'voce', 'voces'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "classificator = VotingClassifier(estimators=[\n",
    "    ('svm', SVC(kernel='linear')),\n",
    "    ('naive', MultinomialNB(alpha=.01))]\n",
    ")\n",
    "\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o sport',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "labels = [1, 1, -1, -1, 0, 0]\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('portuguese'),\n",
    "                                analyzer='word', ngram_range=(1, 1),\n",
    "                                lowercase=True, use_idf=True,\n",
    "                                strip_accents='unicode')\n",
    "\n",
    "features = tf_vectorizer.fit_transform(training_set)\n",
    "classificator.fit(features, labels)\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro']\n",
    "vector_tweets = tf_vectorizer.transform(tweets)\n",
    "predictions = classificator.predict(vector_tweets)\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o cruzeiro jogou muito bem -> 2\n",
      "parabéns pela vitória cruzeiro -> 3\n",
      "ainda acho o cruzeiro ruim -> 2\n",
      "o cruzeiro não jogou bem -> 2\n",
      "cruzeiro jogou contra o sport -> 4\n",
      "primeira rodada o cruzeiro enfrentou o sport -> 5\n",
      "bela vitória do cruzeiro -> 2\n",
      "mais uma vitória do cruzeiro -> 2\n",
      "--------------------------------------------------------------------------------\n",
      "Tweets mais relevantes:\n",
      "['primeira rodada o cruzeiro enfrentou o sport']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compare_tweet_jaccard(tweet, tweet_compare):\n",
    "    words_tweet = tweet.lower().split()\n",
    "    words_compare = tweet_compare.lower().split()\n",
    "    intersection = set(words_tweet).intersection(set(words_compare))\n",
    "    intersection_size = len(intersection)\n",
    "    calc = float(intersection_size) / (len(words_tweet) + len(words_compare)\n",
    "                                       - intersection_size)\n",
    "\n",
    "    if calc >= 0.20:  # Define o quao semelhante é um tweet com o outro\n",
    "        return True  # se tweet igual a tweet_compare\n",
    "    return False\n",
    "\n",
    "\n",
    "tweets = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "          'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "          'cruzeiro jogou contra o sport',\n",
    "          'primeira rodada o cruzeiro enfrentou o sport',\n",
    "          'bela vitória do cruzeiro', 'mais uma vitória do cruzeiro']\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(\n",
    "            stop_words=stopwords.words('portuguese'), analyzer='word',\n",
    "            ngram_range=(1, 1), lowercase=True, use_idf=True)\n",
    "matrix = tf_vectorizer.fit_transform(tweets)\n",
    "\n",
    "feature_array = np.array(tf_vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(matrix.toarray()).flatten()[::-1]\n",
    "feature_words = feature_array[tfidf_sorting][:10]\n",
    "featured_tweets = []\n",
    "for tweet in tweets:\n",
    "    relevance = 0\n",
    "    for word in feature_words:\n",
    "        if word in tweet:\n",
    "            relevance += 1\n",
    "    if relevance > 3:\n",
    "        featured_tweets.append((tweet, relevance))\n",
    "\n",
    "    print(f'{tweet} -> {relevance}')\n",
    "\n",
    "# eliminate duplicated tweets\n",
    "non_duplicated = []\n",
    "for t in sorted(featured_tweets, key=itemgetter(1), reverse=True):\n",
    "    if not non_duplicated:\n",
    "        non_duplicated.append(t[0])\n",
    "    else:\n",
    "        for nd in non_duplicated:\n",
    "            if not compare_tweet_jaccard(nd, t[0]):\n",
    "                non_duplicated.append(t[0])\n",
    "\n",
    "\n",
    "print(80 * '-')\n",
    "print('Tweets mais relevantes:')\n",
    "print(non_duplicated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
