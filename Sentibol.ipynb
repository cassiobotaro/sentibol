{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sentibol\n",
    "\n",
    "![](https://pbs.twimg.com/profile_images/378800000862014558/wxkLU179_400x400.png)\n",
    "#### apresentação gentilmente cedida por Cássio Botaro\n",
    "\n",
    "[github@cassiobotaro/sentibol](https://github.com/cassiobotaro/sentibol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viniWS/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "/Users/viniWS/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Processamento de dados\n",
    "import string\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "# Dados de apoio para classifcação\n",
    "from nltk.corpus import stopwords\n",
    "from emoticons import positive_emoticons, negative_emoticons, positive_sentiment, negative_sentiment\n",
    "\n",
    "# Extração de features\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Classificadores\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/viniWS/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/viniWS/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Definindo o classificador Support Vector Machine\n",
    "classificator = SVC(kernel='linear')\n",
    "\n",
    "# E o set de treinamento, com 6 tweets\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o são paulo',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "\n",
    "# Esse primeiro set vamos botar os labels \"na mão\"\n",
    "labels = [1, 1, -1, -1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o vetorizador de palavras\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('portuguese'),\n",
    "                                analyzer='word', ngram_range=(1, 1),\n",
    "                                lowercase=True, use_idf=True,\n",
    "                                strip_accents='unicode')\n",
    "\n",
    "# Transformando nossos dados com o vetorizador\n",
    "features = tf_vectorizer.fit_transform(training_set)\n",
    "\n",
    "# \"Fittando\" nossos dados no classificador SVC\n",
    "classificator.fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://imgur.com/Hu0DPAv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://imgur.com/RMIc5bd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n"
     ]
    }
   ],
   "source": [
    "# Definindo Tweets para teste\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro']\n",
    "\n",
    "# Vetorizando\n",
    "vector_tweets = tf_vectorizer.transform(tweets)\n",
    "\n",
    "# Calculando predições\n",
    "predictions = classificator.predict(vector_tweets)\n",
    "\n",
    "# Imprimindo predições\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testando com o classificador Naive Bayes\n",
    "![](https://www.inria.fr/var/inria/storage/images/medias/saclay/innovation-images/chapo/saclay-riidata-scikit-learn-260x195/1111030-1-fre-FR/saclay-riidata-scikit-learn-260x195_vignette.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "classificator = MultinomialNB(alpha=.01)\n",
    "\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o sport',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "labels = [1, 1, -1, -1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "classificator = MultinomialNB(alpha=.01)\n",
    "\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o sport',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "labels = [1, 1, -1, -1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('portuguese'),\n",
    "                                analyzer='word', ngram_range=(1, 1),\n",
    "                                lowercase=True, use_idf=True,\n",
    "                                strip_accents='unicode')\n",
    "\n",
    "features = tf_vectorizer.fit_transform(training_set)\n",
    "classificator.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n"
     ]
    }
   ],
   "source": [
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro']\n",
    "\n",
    "vector_tweets = tf_vectorizer.transform(tweets)\n",
    "predictions = classificator.predict(vector_tweets)\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n",
      "cruzeiro! :) -> 1\n",
      "Jogo morno entre cruzeiro e são paulo -> 0\n",
      "Meu sport perdeu hoje :'( -> -1\n"
     ]
    }
   ],
   "source": [
    "# lists based on https://en.wikipedia.org/wiki/List_of_emoticons\n",
    "# Versão original removia pontuação(o que é errado, pois emoticons são feitos utilizando pontuação)\n",
    "# falta de emojis\n",
    "# deveria trazer as palavras a sua raiz\n",
    "\n",
    "list_emoticons_positive = positive_emoticons.split('\\n')\n",
    "list_emoticons_negative = negative_emoticons.split('\\n')\n",
    "list_negative = negative_sentiment.split('\\n')\n",
    "list_positive = positive_sentiment.split('\\n')\n",
    "\n",
    "\n",
    "def classify(text):\n",
    "    for t in text.split(' '):\n",
    "        if t in list_emoticons_positive:\n",
    "            return 1\n",
    "        elif t in list_emoticons_negative:\n",
    "            return -1\n",
    "    return votation(text)\n",
    "\n",
    "\n",
    "def votation(text):\n",
    "    vote = 0\n",
    "    text = clean_text(text)\n",
    "\n",
    "    for t in text:\n",
    "        if t in list_negative:\n",
    "            vote = vote - 1\n",
    "        elif t in list_positive:\n",
    "            vote = vote + 1\n",
    "\n",
    "    if vote > 1:\n",
    "        return 1\n",
    "    elif vote < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return vote\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    token_text = word_tokenize(text.lower())\n",
    "    text = (word for word in token_text\n",
    "            if word not in stopwords.words('portuguese'))\n",
    "    return text\n",
    "\n",
    "\n",
    "def predict(tweets):\n",
    "    return np.array([classify(phrase) for phrase in tweets])\n",
    "\n",
    "\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro', 'cruzeiro! :)',\n",
    "          'Jogo morno entre cruzeiro e são paulo',\n",
    "          'Meu sport perdeu hoje :\\'(']\n",
    "\n",
    "predictions = predict(tweets)\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruzeiro tem um bom time -> 1\n",
      "acompanhe os jogos da primeira rodada -> 0\n",
      "muito ruim esse jogo do cruzeiro -> -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viniWS/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "classificator = VotingClassifier(estimators=[\n",
    "    ('svm', SVC(kernel='linear')),\n",
    "    ('naive', MultinomialNB(alpha=.01))]\n",
    ")\n",
    "\n",
    "training_set = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "                'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "                'cruzeiro jogou contra o sport',\n",
    "                'primeira rodada o cruzeiro enfrentou o sport']\n",
    "labels = [1, 1, -1, -1, 0, 0]\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('portuguese'),\n",
    "                                analyzer='word', ngram_range=(1, 1),\n",
    "                                lowercase=True, use_idf=True,\n",
    "                                strip_accents='unicode')\n",
    "\n",
    "features = tf_vectorizer.fit_transform(training_set)\n",
    "classificator.fit(features, labels)\n",
    "tweets = ['cruzeiro tem um bom time', 'acompanhe os jogos da primeira rodada',\n",
    "          'muito ruim esse jogo do cruzeiro']\n",
    "vector_tweets = tf_vectorizer.transform(tweets)\n",
    "predictions = classificator.predict(vector_tweets)\n",
    "for prediction, tweet in zip(predictions, tweets):\n",
    "    print(f'{tweet} -> {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o cruzeiro jogou muito bem -> 2\n",
      "parabéns pela vitória cruzeiro -> 3\n",
      "ainda acho o cruzeiro ruim -> 2\n",
      "o cruzeiro não jogou bem -> 2\n",
      "cruzeiro jogou contra o sport -> 4\n",
      "primeira rodada o cruzeiro enfrentou o sport -> 5\n",
      "bela vitória do cruzeiro -> 2\n",
      "mais uma vitória do cruzeiro -> 2\n",
      "--------------------------------------------------------------------------------\n",
      "Tweets mais relevantes:\n",
      "['primeira rodada o cruzeiro enfrentou o sport']\n"
     ]
    }
   ],
   "source": [
    "def compare_tweet_jaccard(tweet, tweet_compare):\n",
    "    words_tweet = tweet.lower().split()\n",
    "    words_compare = tweet_compare.lower().split()\n",
    "    intersection = set(words_tweet).intersection(set(words_compare))\n",
    "    intersection_size = len(intersection)\n",
    "    calc = float(intersection_size) / (len(words_tweet) + len(words_compare)\n",
    "                                       - intersection_size)\n",
    "\n",
    "    if calc >= 0.20:  # Define o quao semelhante é um tweet com o outro\n",
    "        return True  # se tweet igual a tweet_compare\n",
    "    return False\n",
    "\n",
    "\n",
    "tweets = ['o cruzeiro jogou muito bem', 'parabéns pela vitória cruzeiro',\n",
    "          'ainda acho o cruzeiro ruim', 'o cruzeiro não jogou bem',\n",
    "          'cruzeiro jogou contra o sport',\n",
    "          'primeira rodada o cruzeiro enfrentou o sport',\n",
    "          'bela vitória do cruzeiro', 'mais uma vitória do cruzeiro']\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(\n",
    "            stop_words=stopwords.words('portuguese'), analyzer='word',\n",
    "            ngram_range=(1, 1), lowercase=True, use_idf=True)\n",
    "matrix = tf_vectorizer.fit_transform(tweets)\n",
    "\n",
    "feature_array = np.array(tf_vectorizer.get_feature_names())\n",
    "tfidf_sorting = np.argsort(matrix.toarray()).flatten()[::-1]\n",
    "feature_words = feature_array[tfidf_sorting][:10]\n",
    "featured_tweets = []\n",
    "for tweet in tweets:\n",
    "    relevance = 0\n",
    "    for word in feature_words:\n",
    "        if word in tweet:\n",
    "            relevance += 1\n",
    "    if relevance > 3:\n",
    "        featured_tweets.append((tweet, relevance))\n",
    "\n",
    "    print(f'{tweet} -> {relevance}')\n",
    "\n",
    "# eliminate duplicated tweets\n",
    "non_duplicated = []\n",
    "for t in sorted(featured_tweets, key=itemgetter(1), reverse=True):\n",
    "    if not non_duplicated:\n",
    "        non_duplicated.append(t[0])\n",
    "    else:\n",
    "        for nd in non_duplicated:\n",
    "            if not compare_tweet_jaccard(nd, t[0]):\n",
    "                non_duplicated.append(t[0])\n",
    "\n",
    "\n",
    "print(80 * '-')\n",
    "print('Tweets mais relevantes:')\n",
    "print(non_duplicated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://s5047.pcdn.co/wp-content/uploads/2015/04/drop_shadows_background2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sugestões de atividades\n",
    "\n",
    "### 1. Implementar um classificador para outro conjunto de dados de Tweets. ++bônus se os dados forem serializados.\n",
    "\n",
    "### 2. Encontrar um conjunto de dados públicos na internet e propôr um fluxograma para análise, incluindo o modelo/algoritmo de escolha.\n",
    "\n",
    "### 3. Fazer contribuições para notebooks disponíveis publicamente.\n",
    "\n",
    "##### Aqui tem alguns para servir de exemplo ;)\n",
    "`git clone https://github.com/vinisalazar/CursoCCB.git`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Muito obrigado!\n",
    "\n",
    "### Apresentações disponíveis em \n",
    "\n",
    "- https://vinisalazar.github.io/aula_nlp/introducao_jupyter.slides.html#/\n",
    "- https://vinisalazar.github.io/aula_nlp/analise_sentimentos.slides.html\n",
    "- http://vinisalazar.github.io/sentibol/Sentibol.slides.html\n",
    "\n",
    "#### Me sigam no GitHub!\n",
    "[https://github.com/vinisalazar](https://github.com/vinisalazar)\n",
    "\n",
    "vinicius.salazar@neoprospecta.com\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
